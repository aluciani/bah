#include "iostream.bah"

#include "./globals.bah"


#define tokenType int

const TOKEN_NO_TYPE =      <tokenType>-1
const TOKEN_TYPE_INT =     <tokenType>0
const TOKEN_TYPE_FLOAT =   <tokenType>1
const TOKEN_TYPE_VAR =     <tokenType>2
const TOKEN_TYPE_ENCL =    <tokenType>3
const TOKEN_TYPE_SEP =     <tokenType>4
const TOKEN_TYPE_STR =     <tokenType>5
const TOKEN_TYPE_KEYWORD = <tokenType>6
const TOKEN_TYPE_CHAR =    <tokenType>7
const TOKEN_TYPE_BOOL =    <tokenType>8
const TOKEN_TYPE_SYNTAX =  <tokenType>10
const TOKEN_TYPE_FUNC =    <tokenType>11


struct Tok {
    cont: cpstring = ""
    ogCont: cpstring
    type: tokenType = TOKEN_NO_TYPE
    pos: int = 0
    line: int = 1
    bahType: cpstring = ""
    isValue: bool = false
    isFunc: bool = false
}

inArray(needle char, arr []char) bool {
    i=0; for i < len(arr) {
        if needle == arr[i] {
            return true
        }
        i = i + 1
    }
    return false
}

inArrayStr(needle cpstring, arr []cpstring) bool {
    i=0; for i < len(arr) {
        if needle == arr[i] {
            return true
        }
        i = i + 1
    }
    return false
}

makeToken(pos int, lineNb int, cont []char, type tokenType) Tok {
    t = Tok{}
    t.cont = arrToStr(cont)
    t.ogCont = t.cont
    clear(cont)
    t.pos = pos
    t.line = lineNb
    t.type = type
    if type == TOKEN_TYPE_INT {
        t.isValue = true
    } else if type == TOKEN_TYPE_STR {
        t.isValue = true
    } else if type == TOKEN_TYPE_FLOAT {
        t.isValue = true
    } else if type == TOKEN_TYPE_VAR {
        t.isValue = true
    }if type == TOKEN_TYPE_BOOL {
        t.isValue = true
    } else if type == TOKEN_TYPE_CHAR {
        t.isValue = true
    }
    return t
}

isMinus(c char, nc char) bool {
    if c == '-' {
        if isNumber(nc) {
            return true
        }
    }
    return false
}

lexerErr(line int, pos int, msg cpstring) {
    lineStr = intToStr(line)
    posStr = intToStr(pos)
    println("\e[1;31m[LEXER-ERROR]\e[0m "+compilerState.currentFile+":"+lineStr+":"+posStr+"\n\e[0m\n"+msg)
    exit(1)
}

lexer(s cpstring) []Tok {
    tokens = []Tok
    
    code = string(s)
    SOURCE = code

    memory = []char

    lineNb = 1

    enclavers = []char{'(', ')', '{', '}', '[', ']'}
    syntaxes = []char{'!', '=', '|', <char>38, '%', '+', '-', '*', '/', ',', '<', '>', ':', <char>59}
                                     //&                                                    //;
    keywords = []cpstring{"if", "else", "for", "struct", "const", "return", "extend", "new", "break", "continue", "default", "switch", "case", "while", "typedef", "function"}
                        //  x      x      x        x        x         x         x       x       x          x          -          -        -       -         -           x
                        // x: done
                        //  : not done
                        // -: not planned
    varChars = []char{'_'}
    seps = []char{'.'}


    i=0; for i < code.length {
        c = code.charAt(i)
        nci = i + 1
        nc char = <char>0
        if nci < code.length {
            nc = code.charAt(i+1)
        }
        if c == '/' {
            nc = code.charAt(i+1)
            if nc == '/' {
                for i < code.length {
                    c = code.charAt(i)
                    if c == <char>10 {
                        break
                    }
                    i = i + 1
                }
                max = code.length - 1
                if i >= max {
                    break
                }
            }
        }

        if c == <char>10 {
            lineNb = lineNb + 1
        }

        //token is a string
        if c == <char>34 {
            pos = i
            memory[0] = c
            i = i + 1
            for i < code.length {
                c = code.charAt(i)
                pc = code.charAt(i - 1) 
                if c == <char>34 {
                    if pc != <char>92 {
                        memory[len(memory)] = c
                        break
                    }
                }
                if c == <char>10 {
                    if pc != <char>92 {
                        memory[len(memory)] = <char>92
                        c = 'n'
                    }
                }
                memory[len(memory)] = c
                i = i + 1
            }
            tokens[len(tokens)] = makeToken(pos, lineNb, memory, TOKEN_TYPE_STR)
        } else if isNumber(c) || isMinus(c, nc) {
        //token is a number
            memory[0] = c
            pos = i
            i = i + 1
            currentType = TOKEN_TYPE_INT
            for i < code.length {
                c = code.charAt(i)
                if c == <char>46 {
                    currentType = TOKEN_TYPE_FLOAT
                } else if isNumber(c) == 0 {
                    break
                }
                memory[len(memory)] = c
                i = i + 1
            }
            i = i - 1
            tokens[len(tokens)] = makeToken(pos, lineNb, memory, currentType)
        } else if c == <char>39 {
        //is a character
            i = i + 1
            n = code.charAt(i)
            toInt = intToStr(<int>nc)
            memory = strToArr(toInt)
            i = i + 1
            c = code.charAt(i)
            if c != <char>39 {
                lexerErr(lineNb, i, "Missing closing tag in char declaration.")
            }
            
            tokens[len(tokens)] = makeToken(i-1, lineNb, memory, TOKEN_TYPE_CHAR)
        } else if c == <char>35 {
        //is a hash keyword
            pos = i
            memory[0] = c
            i = i + 1
            for i < code.length {
                c = code.charAt(i)
                if isAlphaNumeric(c) == 0 {
                    break
                }
                memory[len(memory)] = c
                i = i + 1
            }
            i = i - 1
            memstr = arrAsStr(memory)
            tokens[len(tokens)] = makeToken(pos, lineNb, memory, TOKEN_TYPE_KEYWORD)
        } else if inArray(c, enclavers) {
        //token is enclaver
            memory[0] = c
            tokens[len(tokens)] = makeToken(i, lineNb, memory, TOKEN_TYPE_ENCL)
        } else if inArray(c, syntaxes) {
        //token is a syntax element
            memory[0] = c
            pos = i
            i = i + 1
            fc = c
            for i < code.length {
                c = code.charAt(i)
                if inArray(c, syntaxes) == false {
                    break
                }
                if c == '|' {
                    if fc != c {
                        break
                    }
                } else if c == '&' {
                    if fc != c {
                        break
                    }
                } else if c != '=' {
                    if c != '>' {
                        break
                    }
                }
                memory[len(memory)] = c
                i = i + 1
            }
            i = i - 1
            tokens[len(tokens)] = makeToken(pos, lineNb, memory, TOKEN_TYPE_SYNTAX)
        } else if inArray(c, seps) {
            memory[0] = c
            tokens[len(tokens)] = makeToken(i, lineNb, memory, TOKEN_TYPE_SEP)
        } else if isAlphaNumeric(c) || inArray(c, varChars) {
            memory[0] = c
            pos = i
            i = i + 1
            for i < code.length {
                c = code.charAt(i)

                if isAlphaNumeric(c) == 0 {
                    if inArray(c, varChars) == false {
                        if c == '>' {
                            lc = memory[len(memory)-1]
                            if lc == '-' {
                                memory[len(memory)-1] = <char>0
                                i = i - 1
                                break
                            }
                        }
                        
                        break
                    }
                }

                memory[len(memory)] = c
                i = i + 1
            }
            i = i - 1
            currentType = TOKEN_TYPE_VAR
            
            memstr = arrAsStr(memory)
            
            if inArrayStr(memstr, keywords) {
                currentType = TOKEN_TYPE_KEYWORD
            }
            // else if inArrayStr(memstr, bools) {
            //     currentType = TOKEN_TYPE_BOOL
            // }

            tokens[len(tokens)] = makeToken(pos, lineNb, memory, currentType)

        }

        i = i + 1
    }
    totalLines = totalLines + lineNb - 1
    return tokens
}